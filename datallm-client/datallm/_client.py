import math
from typing import Optional, Union, List, Dict, Any
from warnings import warn

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    retry_if_exception_message,
)
import pandas as pd
from rich.progress import (
    BarColumn,
    Progress,
    TaskProgressColumn,
    TextColumn,
    TimeElapsedColumn,
    track,
)
from rich.style import Style

from ._base_client import SyncClient
from ._pd_utils import (
    _convert_values_to_series,
)
from ._resources import SyncRowCompletionsResource, SyncModelsResource
from ._types import DtypeEnum, NamedValue, CompletionUsage
from ._exceptions import APIStatusError


class DataLLM(SyncClient):
    def __init__(self, base_url=None, api_key=None):
        super().__init__(base_url=base_url, api_key=api_key)
        self.row_completions = SyncRowCompletionsResource(self)
        self._models = SyncModelsResource(self)
        self.usage = CompletionUsage(
            completion_tokens=0, prompt_tokens=0, total_tokens=0
        )

    def models(self):
        return self._models.list()

    def enrich(
        self,
        data: Union[pd.DataFrame, pd.Series],
        prompt: str,
        data_description: Optional[str] = None,
        dtype: Union[str, DtypeEnum] = None,
        regex: Optional[str] = None,
        categories: Optional[list[str]] = None,
        max_tokens: Optional[int] = 16,
        temperature: Optional[float] = 0.7,
        top_p: Optional[float] = 1.0,
        model: Optional[str] = None,
        progress_bar: bool = True,
    ) -> pd.Series:
        """
        Creates a new pd.Series given the context of a pd.DataFrame. This allows to easily enrich a DataFrame with new
        values generated by DataLLM.

        Args:
            data: The existing values used as context for the newly generated values. The returned values
            will be of same length and in the same order as the provided list of values.
            prompt: The prompt for generating the returned values.
            data_description: Additional information regarding the context of the provided values.
            dtype: The dtype of the returned values. One of `string`, `category`, `integer`, `float`, `boolean`, `date`
            or `datetime`.
            regex: A regex used to limit the generated values.
            categories: The allowed values to be sampled from. If provided, then the dtype is set to `category`.
            max_tokens: The maximum number of tokens to generate. Only applicable for string dtype.
            temperature: The temperature used for sampling.
            top_p: The top_p used for nucleus sampling.
            model: The model used for generating new values. Check available models with `datallm.models.list()`. The
            default model is the first model in that list.
            progress_bar: Whether to show a progress bar.
        """
        if data is None or not isinstance(data, (pd.DataFrame, pd.Series)):
            raise ValueError("data must be a pandas DataFrame or Series")
        if not prompt:
            raise ValueError("prompt must be a non-empty string")

        # set default values
        if model is None:
            model = self.models()[0]
        if dtype is None:
            if isinstance(categories, list) and len(categories) > 0:
                dtype = DtypeEnum.category
            else:
                dtype = DtypeEnum.string
        if dtype != DtypeEnum.string:
            max_tokens = None
        if dtype == DtypeEnum.category and not categories:
            raise ValueError("Categories must be provided when dtype is category")

        if isinstance(data, pd.Series):
            data = pd.DataFrame(data)

        chunk_size = 100
        num_chunks = math.ceil(data.shape[0] / chunk_size)
        values: List[str] = []
        progress = Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(
                style=Style(color="rgb(245,245,245)"),
                complete_style=Style(color="rgb(66,77,179)"),
                finished_style=Style(color="rgb(36,219,149)"),
                pulse_style=Style(color="rgb(245,245,245)"),
            ),
            TaskProgressColumn(),
            TimeElapsedColumn(),
        )
        try:
            df_chunks = [
                data.iloc[i : i + chunk_size]
                for i in range(0, data.shape[0], chunk_size)
            ]
            for df_chunk in track(
                df_chunks,
                description=f"{prompt[:30]:<30}",
                total=num_chunks,
                disable=not progress_bar,
            ):
                completion_row_values = [
                    [NamedValue(name=str(name), value=str(row[name])) for name in row.index]
                    for _, row in df_chunk.iterrows()
                ]

                @retry(
                    retry=retry_if_exception_type(APIStatusError)
                    & retry_if_exception_message(
                        match=r"HTTP error occurred: (408|429|503|504)"
                    ),
                    stop=stop_after_attempt(5),
                    wait=wait_exponential(multiplier=1, max=10),
                )
                def make_api_call():
                    return self.row_completions.create(
                        model=model,
                        prompt=prompt,
                        dtype=dtype,
                        categories=categories,
                        data_description=data_description,
                        regex=regex,
                        rows=completion_row_values,
                        max_tokens=max_tokens,
                        temperature=temperature,
                        top_p=top_p,
                    )

                result = make_api_call()
                values += result.values
                self.usage.completion_tokens += result.usage.completion_tokens
                self.usage.prompt_tokens += result.usage.prompt_tokens
                self.usage.total_tokens += result.usage.total_tokens
        except KeyboardInterrupt:
            progress.stop()
            warn("Process interrupted. Returning the completions generated so far.")
            data = data.head(len(values))

        series = _convert_values_to_series(values, dtype)
        series.name = prompt
        series.index = data.index
        return series

    def mock(
        self,
        n: int,
        data_description: Optional[str] = None,
        columns: Union[List[str], Dict[str, Any]] = None,
        temperature: Optional[float] = 0.7,
        top_p: Optional[float] = 1.0,
        model: Optional[str] = None,
        progress_bar: bool = True,
    ) -> pd.DataFrame:
        """
        Create a pd.DataFrame from scratch using DataLLM. This will create one column after the other for as many rows
        as requested. Note, that rows are sampled independently of each other, and thus may contain duplicates.

        Args:
            n: The number of generated rows.
            default model is the first model in that list.
            data_description: Additional information regarding the context of the provided values.
            columns: Either a list of column names. Or a dict, with column names as keys, and sampling parameters as
            values. These may contain `prompt`, `dtype`, `regex`, `categories`, `max_tokens`, `temperature`, `top_p`.
            temperature: The temperature used for sampling. Can be overwritten on a per-column basis.
            top_p: The top_p used for nucleus sampling. Can be overwritten on a per-column basis.
            model: The model used for generating new values. Check available models with `datallm.models.list()`. The
            progress_bar: Whether to show a progress bar.
        """

        df = pd.DataFrame(index=range(n))
        if n is None:
            raise ValueError("n must be a positive integer")
        if columns is None:
            raise ValueError("columns must be a list or a dict")
        if model is None:
            model = self.models()[0]
        if isinstance(columns, list):
            if len(set(columns)) < len(columns):
                raise ValueError("column names must be unique")
            columns = {col: {} for col in columns}
        col_names = list(columns.keys())
        for col, params in columns.items():
            # we temporarily include the prompt to the column name to pass this context on to subsequent cols
            tmp_col = f"{col} ({params['prompt']})" if "prompt" in params else col
            df[tmp_col] = self.enrich(
                data=df,
                prompt=params.get("prompt", col),
                model=model,
                data_description=data_description,
                dtype=params.get("dtype", None),
                regex=params.get("regex", None),
                categories=params.get("categories", None),
                max_tokens=params.get("max_tokens", None),
                temperature=params.get("temperature", temperature),
                top_p=params.get("top_p", top_p),
                progress_bar=progress_bar,
            )
        # set column names to the provided keys
        df.columns = col_names
        return df
